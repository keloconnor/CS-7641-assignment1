{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn'])\n",
    "bank_df = pd.read_csv(\"~\\\\banking_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_scores, val_scores, indices, title):\n",
    "    plt.plot(indices, train_scores , \"g-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Training Instances Used')\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "        \n",
    "def plot_complexity(train_scores, val_scores, indices, title):\n",
    "    plt.plot(indices, train_scores , \"g-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.gca().invert_xaxis()\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone    \n",
    "\n",
    "def stratFold(train_X_all, train_y_all, classifier, metric, average=None,\n",
    "              fold=5):\n",
    "    train_metric, val_metric, indices = [], [], []\n",
    "    for m in range(100, len(train_X_all), 100):\n",
    "        skfolds = StratifiedKFold(n_splits=fold)\n",
    "        metric_list = []\n",
    "        metric_list_train = []\n",
    "        train_X = train_X_all[:m]\n",
    "        train_y = train_y_all[:m]\n",
    "        for train_index, test_index in skfolds.split(train_X, train_y):\n",
    "            train_X_folds = train_X.iloc[train_index]\n",
    "            train_y_folds = train_y.iloc[train_index]\n",
    "            test_X_fold = train_X.iloc[test_index]\n",
    "            test_y_fold = train_y.iloc[test_index]\n",
    "            classifier.fit(train_X_folds.values, train_y_folds.values.ravel())\n",
    "            train_y_folds_pred = classifier.predict(train_X_folds)\n",
    "            test_y_fold_pred = classifier.predict(test_X_fold)\n",
    "            if average:\n",
    "                metric_list.append(metric(test_y_fold.values, test_y_fold_pred,\n",
    "                                     average=average))\n",
    "                metric_list_train.append(metric(train_y_folds.values, train_y_folds_pred, \n",
    "                                            average=average))\n",
    "            else:\n",
    "                metric_list.append(metric(test_y_fold.values, test_y_fold_pred))\n",
    "                metric_list_train.append(metric(train_y_folds.values, train_y_folds_pred))\n",
    "                \n",
    "        test_avg = sum(metric_list)/len(metric_list)\n",
    "        train_avg = sum(metric_list_train)/len(metric_list_train)\n",
    "        val_metric.append(test_avg)\n",
    "        train_metric.append(train_avg)\n",
    "        indices.append(m)\n",
    "    \n",
    "    return train_metric, val_metric, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = bank_df.values # convert to numpy array\n",
    "print(x.shape)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "print(x_scaled.shape)\n",
    "bank_df = pd.DataFrame(x_scaled, columns=bank_df.columns)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "data_split = StratifiedShuffleSplit(n_splits=1 , test_size=0.3, random_state=30)\n",
    "for train_ind, test_ind in data_split.split(bank_df, bank_df[\"Bankrupt\"]):\n",
    "    strat_train_set = bank_df.loc[train_ind]\n",
    "    strat_test_set = bank_df.loc[test_ind]\n",
    "    \n",
    "train_set = strat_train_set\n",
    "test_set = strat_test_set\n",
    "\n",
    "train_y = train_set[[\"Bankrupt\"]]\n",
    "train_X = train_set.drop(\"Bankrupt\", axis=1)\n",
    "test_y = test_set[[\"Bankrupt\"]]\n",
    "test_X = test_set.drop(\"Bankrupt\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bank_knn = KNeighborsClassifier()\n",
    "bank_knn.fit(train_X, train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(bank_knn, train_X, train_y.values.ravel(),\n",
    "                         scoring=\"f1_macro\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores = stratFold(train_X, train_y, bank_knn, f1_score, average=\"macro\")\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"F1 MACRO score learning curve \")\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "bank_improved_knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                             metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
    "                             weights='uniform')\n",
    "\n",
    "param_range = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    bank_improved_knn, train_X, train_y.values.ravel(), param_name=\"n_neighbors\", param_range=param_range,\n",
    "    scoring='f1_macro', verbose=1, cv=10, n_jobs=-1\n",
    ")\n",
    "print(train_scores.mean(axis=1), test_scores.mean(axis=1), param_range)\n",
    "plot_complexity(train_scores.mean(axis=1), test_scores.mean(axis=1), param_range, \n",
    "                title='F1 MACRO on n_neighbors', inverse_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "best_bank_knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                             metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
    "                             weights='distance')\n",
    "\n",
    "f1_scores = stratFold(train_X, train_y, best_bank_knn, f1_score, \n",
    "                      average='macro')\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_macro score learning curve with best knn\")\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_score, accuracy_score, average_precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "best_bank_knn.fit(train_X, train_y)\n",
    "test_predictions = best_bank_knn.predict(test_X)\n",
    "print(classification_report(test_y, test_predictions,digits=4,zero_division=True))\n",
    "print(confusion_matrix(test_y, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(best_bank_knn, train_X, train_y.values.ravel(),\n",
    "                         scoring=\"f1_macro\", cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

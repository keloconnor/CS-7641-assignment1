{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "matplotlib.rc('figure', figsize=[10,5])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn'])\n",
    "bank_df = pd.read_csv(\"~\\\\banking_data.csv\")\n",
    "\n",
    "def plot_learning_curve(train_scores, val_scores, indices, title):\n",
    "    plt.plot(indices, train_scores , \"g-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Training Instances Used')\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "        \n",
    "def plot_complexity(train_scores, val_scores, indices, title):\n",
    "    plt.plot(indices, train_scores , \"g-+\", linewidth=2, label=\"train\")\n",
    "    plt.plot(indices, val_scores, \"b-+\", linewidth=2, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    plt.gca().invert_xaxis()\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone    \n",
    "\n",
    "def stratFold(train_X_all, train_y_all, classifier, metric, average=None,\n",
    "              fold=5):\n",
    "    train_metric, val_metric, indices = [], [], []\n",
    "    for m in range(100, len(train_X_all), 100):\n",
    "        skfolds = StratifiedKFold(n_splits=fold)\n",
    "        metric_list = []\n",
    "        metric_list_train = []\n",
    "        train_X = train_X_all[:m]\n",
    "        train_y = train_y_all[:m]\n",
    "        for train_index, test_index in skfolds.split(train_X, train_y):\n",
    "            train_X_folds = train_X.iloc[train_index]\n",
    "            train_y_folds = train_y.iloc[train_index]\n",
    "            test_X_fold = train_X.iloc[test_index]\n",
    "            test_y_fold = train_y.iloc[test_index]\n",
    "            classifier.fit(train_X_folds.values, train_y_folds.values.ravel())\n",
    "            train_y_folds_pred = classifier.predict(train_X_folds)\n",
    "            test_y_fold_pred = classifier.predict(test_X_fold)\n",
    "            if average:\n",
    "                metric_list.append(metric(test_y_fold.values, test_y_fold_pred,\n",
    "                                     average=average))\n",
    "                metric_list_train.append(metric(train_y_folds.values, train_y_folds_pred, \n",
    "                                            average=average))\n",
    "            else:\n",
    "                metric_list.append(metric(test_y_fold.values, test_y_fold_pred))\n",
    "                metric_list_train.append(metric(train_y_folds.values, train_y_folds_pred))\n",
    "                \n",
    "        test_avg = sum(metric_list)/len(metric_list)\n",
    "        train_avg = sum(metric_list_train)/len(metric_list_train)\n",
    "        val_metric.append(test_avg)\n",
    "        train_metric.append(train_avg)\n",
    "        indices.append(m)\n",
    "    \n",
    "    return train_metric, val_metric, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = bank_df.values # convert to numpy array\n",
    "print(x.shape)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "print(x_scaled.shape)\n",
    "bank_df = pd.DataFrame(x_scaled, columns=bank_df.columns)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "data_split = StratifiedShuffleSplit(n_splits=1 , test_size=0.3, random_state=30)\n",
    "for train_ind, test_ind in data_split.split(bank_df, bank_df[\"Bankrupt\"]):\n",
    "    strat_train_set = bank_df.loc[train_ind]\n",
    "    strat_test_set = bank_df.loc[test_ind]\n",
    "    \n",
    "train_set = strat_train_set\n",
    "test_set = strat_test_set\n",
    "\n",
    "train_y = train_set[[\"Bankrupt\"]]\n",
    "train_X = train_set.drop(\"Bankrupt\", axis=1)\n",
    "test_y = test_set[[\"Bankrupt\"]]\n",
    "test_X = test_set.drop(\"Bankrupt\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bankclf = AdaBoostClassifier()\n",
    "bankclf.fit(train_X, train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(bankclf, train_X, train_y.values.ravel(),\n",
    "                         scoring=\"f1_macro\", cv=10)\n",
    "scores.mean()\n",
    "\n",
    "\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "band_ens_clf = AdaBoostClassifier()\n",
    "f1_scores = stratFold(train_X, train_y, band_ens_clf, f1_score, average='macro')\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"F1 MACRO score learning curve\")\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_score, accuracy_score, average_precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "band_ens_clf.fit(train_X, train_y)\n",
    "test_predictions = band_ens_clf.predict(test_X)\n",
    "print(classification_report(test_y, test_predictions,digits=4,zero_division=True))\n",
    "print(confusion_matrix(test_y, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "params = {\n",
    "    'base_estimator__max_depth': [1, 2],\n",
    "    \"base_estimator__splitter\" : [\"best\", \"random\"],\n",
    "    'n_estimators': [15,25, 50]\n",
    "}\n",
    "empty_decision_tree = DecisionTreeClassifier(max_depth=None, class_weight=\"balanced\")\n",
    "adaBoost = AdaBoostClassifier(empty_decision_tree)\n",
    "\n",
    "search_f1 = GridSearchCV(adaBoost, params, cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "search_f1.fit(train_X, train_y.values.ravel())\n",
    "print(search_f1.best_estimator_, search_f1.best_score_)\n",
    "from sklearn.metrics import f1_score\n",
    "f1_scores = stratFold(train_X, train_y, search_f1.best_estimator_, \n",
    "                           f1_score, average=\"macro\")\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_macro score learning curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "empty_decision_tree = DecisionTreeClassifier(max_depth=1, splitter=\"random\", \n",
    "                                             class_weight='balanced')\n",
    "adaBoost = AdaBoostClassifier(empty_decision_tree, learning_rate=0.55, \n",
    "                              n_estimators=70)\n",
    "param_range = np.linspace(10, 500, 50).astype(int)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    adaBoost, train_X, train_y.values.ravel(), param_name=\"n_estimators\", \n",
    "    param_range=param_range, scoring='f1_macro', verbose=1, cv=10, n_jobs=-1\n",
    ")\n",
    "print(train_scores.mean(axis=1), test_scores.mean(axis=1), param_range)\n",
    "plot_complexity(train_scores.mean(axis=1), test_scores.mean(axis=1), param_range, \n",
    "                title='F1 Macro Complexity Curve on n_estimators', inverse_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost = AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
    "                                                         class_weight='balanced',\n",
    "                                                         criterion='gini',\n",
    "                                                         max_depth=2),\n",
    "                   learning_rate=0.55, n_estimators=60, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "f1_scores = stratFold(train_X, train_y, best_adaboost, f1_score, \n",
    "                      average='macro')\n",
    "plot_learning_curve(f1_scores[0], f1_scores[1], f1_scores[2], \n",
    "                    title=\"f1_macro score learning curve with best adaboost\")\n",
    "\n",
    "elapsed = (time.time() - start)\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(best_adaboost, train_X, train_y.values.ravel(),\n",
    "                         scoring=\"f1_macro\", cv=10, n_jobs=-1)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
